# -*- coding: utf-8 -*-
"""final_data_ml.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19F2xl_fppo47oa3SbRzHUfcNR2bvjLMz
"""

import pandas as pd
import os
import numpy as np
from itertools import chain
import datetime
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.model_selection import GridSearchCV
from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import KFold
from sklearn.metrics import confusion_matrix, recall_score, accuracy_score, precision_score, f1_score

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/MyDrive/Github

source_dir=r'./Stress-Predict-Dataset-main/Raw_data/'  #source directory

def read_data():
  df=pd.read_csv(os.path.join(source_dir,"dataset","Stress_dataset.csv"))
  return df

def preprocess(df):    #preprocessing of data
  df=df.fillna(method='ffill') #filling missing values
  df=df.drop(columns=['Unnamed: 0.1','Unnamed: 0'], axis=1) #droping extra columns
  df['Date and time']=pd.to_datetime(df['Date and time'])
  df['hour'] = df['Date and time'].dt.hour
  df['day_of_week'] = df['Date and time'].dt.dayofweek
  df['month'] = df['Date and time'].dt.month
  df['year'] = df['Date and time'].dt.year
  df = pd.get_dummies(df, columns=['day_of_week', 'month'])
  df=df.drop(columns=['Date and time','samples'])
  return df

def spliting_data(df):  #spliting data into train and test
  X=df.drop(columns=['label'])
  Y=df['label']
  X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2,shuffle=True ,random_state=2)
  return X_train, X_test, y_train, y_test

def training_model(X_train,y_train, clf): #training the model

  # Train Decision Tree Classifer
  clf = clf.fit(X_train,y_train)
  return clf

def prediction_and_test(X_test,y_test, clf):
  y_pred = clf.predict(X_test) #prediction
  #Test results
  print("Accuracy:",accuracy_score(y_test, y_pred))
  print("Confusion matrix:", confusion_matrix(y_test, y_pred))
  print("recall score:",recall_score(y_test, y_pred))
  print("precision score:",precision_score(y_test, y_pred))
  print("f1 score:",f1_score(y_test, y_pred))

def K_fold_validation(rf, df):
  X=df.drop(columns=['label'])
  Y=df['label']
  kf = KFold(n_splits=5, shuffle=True, random_state=42)
  #Validation
  for train_index, test_index in kf.split(X, Y):
    X_train, X_test = X.iloc[train_index], X.iloc[test_index]
    y_train, y_test = Y.iloc[train_index], Y.iloc[test_index]
    rf.fit(X_train, y_train)
    score = rf.score(X_test, y_test)
    print("Accuracy: ", score)

def main():
  df=read_data()
  df=preprocess(df)
  X_train, X_test, y_train, y_test=spliting_data(df)
  clf=DecisionTreeClassifier() #declaring decision tree model
  clf=training_model(X_train, y_train, clf)
  prediction_and_test(X_test, y_test, clf)
  parameters = {'max_depth':range(3,20)} #parameter fro max_depth between 3 and 20
  clf2 = GridSearchCV(DecisionTreeClassifier(), parameters, n_jobs=4) #GridSearchCV for hyperparameter tuning
  clf2=training_model(X_train, y_train, clf2) #training GridSearchCV with Decison Tree
  # tree_model = clf2.best_estimator_
  print (clf2.best_score_, clf2.best_params_) #choosing best score and parameter
  rf=RandomForestClassifier() #declaring random forest classifier
  rf=training_model(X_train, y_train, rf) #training
  prediction_and_test(X_test, y_test,rf)
  K_fold_validation(RandomForestClassifier(), df) #validation using k-fold

if __name__=="__main__":
  main() #running the main program